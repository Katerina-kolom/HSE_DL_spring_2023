{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4HaqwymYj6C"
      },
      "source": [
        "# Задание 2 - Перенос обучения (transfer learning) и тонкая настройка (fine-tuning)\n",
        "\n",
        "Одна из важнейшних техник в тренировке сетей - использовать заранее натренированные веса на более общей задаче в качестве начальной точки, а потом \"дотренировать\" их на конкретной.\n",
        "\n",
        "Такой подход и убыстряет обучение, и позволяет тренировать эффективные модели на маленьких наборах данных.\n",
        "\n",
        "В этом упражнении мы натренируем классификатор, который отличает хотдоги от не хотдогов!  \n",
        "\n",
        "Это задание требует доступа к GPU, поэтому его можно выполнять либо на компьютере с GPU от NVidia, либо в [Google Colab](https://colab.research.google.com/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcXBeP1O7cnY"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import csv\n",
        "import urllib\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "from socket import timeout\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# !pip install torch \n",
        "# !pip install torchvision\n",
        "# !pip install Pillow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1OSP-H6Yj6I"
      },
      "source": [
        "Сначала давайте скачаем данные с картинками. Это сделает код в следующей ячейке. Данные будут разделены на две части. На обучающей выборке, которая будет храниться в папке **train_kaggle**, мы будем строить наши модели, а на тестовой выборке **test_kaggle** будем предсказывать класс, к которому относится фотография (хотдог или нет).\n",
        "\n",
        "### Если вы в Google Colab!\n",
        "\n",
        "В нем можно запускать ноутбуки с доступом к GPU. Они не очень быстрые, зато бесплатные!\n",
        "Каждый ноутбук получает свой собственный environment c доступным диском итд.\n",
        "\n",
        "Через 90 минут отсуствия активности этот environment пропадает со всеми данными.\n",
        "Поэтому нам придется скачивать данные каждый раз."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ourBj07Arm3R"
      },
      "outputs": [],
      "source": [
        "# Download train data\n",
        "!wget \"https://storage.googleapis.com/dlcourse_ai/train.zip\"\n",
        "!unzip -q \"train.zip\"\n",
        "\n",
        "train_folder = \"train_kaggle/\"\n",
        "# Count number of files in the train folder, should be 4603\n",
        "print('Number of files in the train folder', len(os.listdir(train_folder)))\n",
        "\n",
        "# Download test data\n",
        "!wget \"https://storage.googleapis.com/dlcourse_ai/test.zip\"\n",
        "!unzip -q \"test.zip\"\n",
        "\n",
        "test_folder = \"test_kaggle/\"\n",
        "# Count number of files in the test folder, should be 1150\n",
        "print('Number of files in the test folder', len(os.listdir(test_folder)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_folder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "E1x30Blhsl4G",
        "outputId": "e18fd841-71f9-4069-945f-c29426fcb940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'train_kaggle/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNU-OD9O9ltP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "from torch.utils.data import Dataset, SubsetRandomSampler\n",
        "from torchvision import transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "device = torch.device(\"cuda:0\") # Let's make sure GPU is available!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOatPvPzYj6J"
      },
      "source": [
        "# Имплементируем свой Dataset для загрузки данных\n",
        "\n",
        "В этом задании мы реализуем свой собственный класс Dataset для загрузки данных. Его цель - загрузить данные с диска и выдать по ним тензор с входом сети, меткой и идентификатором картинки.\n",
        "\n",
        "Вот ссылка, где хорошо объясняется как это делать на примере: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "\n",
        "Ваш Dataset должен в качестве количества сэмплов выдать количество файлов в папке и уметь выдавать кортеж из сэмпла, метки по индексу и названия файла.\n",
        "Если название файла начинается со слов 'frankfurter', 'chili-dog' или 'hotdog' - метка положительная. Иначе отрицательная (ноль).\n",
        "\n",
        "И не забудьте поддержать возможность трансформации входа (аргумент `transforms`), она нам понадобится!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bN2SPiJa9v5M"
      },
      "outputs": [],
      "source": [
        "class HotdogOrNotDataset(Dataset):\n",
        "    def __init__(self, folder, transform=None):\n",
        "        self.transform = transform\n",
        "        \n",
        "        # TODO: Your code here!\n",
        "        \n",
        "    def __len__(self):\n",
        "        # TODO\n",
        "        raise Exception(\"Not implemented!\")\n",
        "    \n",
        "    def __getitem__(self, index):        \n",
        "        # TODO Implement getting item by index\n",
        "        # Hint: os.path.join is helpful!\n",
        "        raise Exception(\"Not implemented!\")\n",
        "        return img, y, img_id\n",
        "\n",
        "def visualize_samples(dataset, indices, title=None, count=10):\n",
        "    # visualize random 10 samples\n",
        "    plt.figure(figsize=(count*3,3))\n",
        "    display_indices = indices[:count]\n",
        "    if title:\n",
        "        plt.suptitle(\"%s %s/%s\" % (title, len(display_indices), len(indices)))        \n",
        "    for i, index in enumerate(display_indices):    \n",
        "        x, y, _ = dataset[index]\n",
        "        plt.subplot(1,count,i+1)\n",
        "        plt.title(\"Label: %s\" % y)\n",
        "        plt.imshow(x)\n",
        "        plt.grid(False)\n",
        "        plt.axis('off')   \n",
        "    \n",
        "orig_dataset = HotdogOrNotDataset(train_folder)\n",
        "indices = np.random.choice(np.arange(len(orig_dataset)), 7, replace=False)\n",
        "\n",
        "visualize_samples(orig_dataset, indices, \"Samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQNsUvYm4_2V"
      },
      "outputs": [],
      "source": [
        "# Let's make sure transforms work!\n",
        "dataset = HotdogOrNotDataset(train_folder, transform=transforms.RandomVerticalFlip(0.9))\n",
        "\n",
        "visualize_samples(dataset, indices, \"Samples with flip - a lot should be flipped!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jhsSnt4Yj6K"
      },
      "source": [
        "# Создаем Dataset для тренировки\n",
        "\n",
        "И разделяем его на train и validation.\n",
        "На train будем обучать модель, на validation проверять ее качество, а соревнование Kaggle In-Class проведем на фотографиях из папки test_kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAvkoRx-9FsP"
      },
      "outputs": [],
      "source": [
        "# First, lets load the dataset\n",
        "train_dataset = HotdogOrNotDataset(train_folder, \n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.Resize((224, 224)),\n",
        "                           transforms.ToTensor(),\n",
        "                           # Use mean and std for pretrained models\n",
        "                           # https://pytorch.org/docs/stable/torchvision/models.html\n",
        "                           transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])                         \n",
        "                       ])\n",
        "                      )\n",
        "test_dataset = HotdogOrNotDataset(test_folder, \n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.Resize((224, 224)),\n",
        "                           transforms.ToTensor(),\n",
        "                           # Use mean and std for pretrained models\n",
        "                           # https://pytorch.org/docs/stable/torchvision/models.html\n",
        "                           transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])                         \n",
        "                       ])\n",
        "                      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRnr8CPg7Hli"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "data_size = len(dataset)\n",
        "validation_fraction = .2\n",
        "\n",
        "\n",
        "val_split = int(np.floor((validation_fraction) * data_size))\n",
        "indices = list(range(data_size))\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "val_indices, train_indices = indices[:val_split], indices[val_split:]\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "val_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
        "                                           sampler=train_sampler)\n",
        "val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                         sampler=val_sampler)\n",
        "# Notice that we create test data loader in a different way. We don't have the labels.\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N1jxdCYYj6L"
      },
      "source": [
        "Наши обычные функции для тренировки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ek3KVQK7hJ6"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, loss, optimizer, num_epochs):    \n",
        "    loss_history = []\n",
        "    train_history = []\n",
        "    val_history = []\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train() # Enter train mode\n",
        "        \n",
        "        loss_accum = 0\n",
        "        correct_samples = 0\n",
        "        total_samples = 0\n",
        "        for i_step, (x, y,_) in enumerate(train_loader):\n",
        "          \n",
        "            x_gpu = x.to(device)\n",
        "            y_gpu = y.to(device)\n",
        "            prediction = model(x_gpu)    \n",
        "            loss_value = loss(prediction, y_gpu)\n",
        "            optimizer.zero_grad()\n",
        "            loss_value.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            _, indices = torch.max(prediction, 1)\n",
        "            correct_samples += torch.sum(indices == y_gpu)\n",
        "            total_samples += y.shape[0]\n",
        "            \n",
        "            loss_accum += loss_value\n",
        "\n",
        "        ave_loss = loss_accum / i_step\n",
        "        train_accuracy = float(correct_samples) / total_samples\n",
        "        val_accuracy = compute_accuracy(model, val_loader)\n",
        "        \n",
        "        loss_history.append(float(ave_loss))\n",
        "        train_history.append(train_accuracy)\n",
        "        val_history.append(val_accuracy)\n",
        "        \n",
        "        print(\"Average loss: %f, Train accuracy: %f, Val accuracy: %f\" % (ave_loss, train_accuracy, val_accuracy))\n",
        "        \n",
        "    return loss_history, train_history, val_history\n",
        "        \n",
        "def compute_accuracy(model, loader):\n",
        "    \"\"\"\n",
        "    Computes accuracy on the dataset wrapped in a loader\n",
        "    \n",
        "    Returns: accuracy as a float value between 0 and 1\n",
        "    \"\"\"\n",
        "    model.eval() # Evaluation mode\n",
        "    # TODO: Copy implementation from previous assignment\n",
        "    # Don't forget to move the data to device before running it through the model!\n",
        "    raise Exception(\"Not implemented\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1t0r_DSYj6M"
      },
      "source": [
        "# Использование заранее натренированной сети (pretrained network)\n",
        "\n",
        "Чаще всего в качестве заранее натренированной сети используется сеть, натренированная на данных ImageNet с 1M изображений и 1000 классами.\n",
        "\n",
        "PyTorch включает такие натренированные сети для различных архитектур (https://pytorch.org/vision/stable/models.html)  \n",
        "Мы будем использовать ResNet18.\n",
        "\n",
        "Для начала посмотрим, что выдает уже натренированная сеть на наших картинках. То есть, посмотрим к какому из 1000 классов их отнесет сеть.\n",
        "\n",
        "Запустите модель на 10 случайных картинках из датасета и выведите их вместе с классами с наибольшей вероятностью.  \n",
        "В коде уже есть код, который формирует соответствие между индексами в выходном векторе и классами ImageNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnvXSmtyLAgz"
      },
      "outputs": [],
      "source": [
        "# Thanks to https://discuss.pytorch.org/t/imagenet-classes/4923/2\n",
        "def load_imagenet_classes():\n",
        "    classes_json = urllib.request.urlopen('https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json').read()\n",
        "    classes = json.loads(classes_json)\n",
        "    \n",
        "    # TODO: Process it to return dict of class index to name\n",
        "    return { int(k): v[-1] for k, v in classes.items()}\n",
        "    \n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# TODO: Run this model on 10 random images of your dataset and visualize what it predicts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a-3a1ZFGEw_"
      },
      "source": [
        "# Перенос обучения (transfer learning) - тренировать только последний слой\n",
        "\n",
        "Существует несколько вариантов переноса обучения, мы попробуем основные.  \n",
        "Первый вариант - заменить последний слой на новый и тренировать только его, заморозив остальные."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCWMUWmr7t5g"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "# TODO: Freeze all the layers of this model and add a new output layer\n",
        "# https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
        "\n",
        "parameters = None   # Fill the right thing here!\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD( parameters, lr=0.001, momentum=0.9)\n",
        "loss_history, train_history, val_history = train_model(model, train_loader, val_loader, loss, optimizer, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dDH4WfaB2Il"
      },
      "source": [
        "# Перенос обучения (transfer learning) - тренировать всю модель\n",
        "\n",
        "Второй вариант - точно так же заменить последгний слой на новый и обучать всю модель целиком."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ss0jilyvuOh"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "# TODO: Add a new output layer and train the whole model\n",
        "# https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
        "parameters = None   # Fill the right thing here!\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD( parameters, lr=0.001, momentum=0.9)\n",
        "\n",
        "loss_history, train_history, val_history = train_model(model, train_loader, val_loader, loss, optimizer, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meQt_vDCs9cc"
      },
      "source": [
        "# Перенос обучения (transfer learning) - разные скорости обучения для разных слоев\n",
        "\n",
        "И наконец последний вариант, который мы рассмотрим - использовать разные скорости обучения для новых и старых слоев"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evro9ksXGs9u"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "# TODO: Add a new output layer\n",
        "# Train new layer with learning speed 0.001 and old layers with 0.0001\n",
        "# https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = None # Hint - look into what PyTorch optimizers let you configure!\n",
        "loss_history, train_history, val_history = train_model(model_conv, train_loader, val_loader, loss, optimizer, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SJbnw9wYj6P"
      },
      "source": [
        "# Визуализируем метрики и ошибки модели\n",
        "\n",
        "Попробуем посмотреть, где модель ошибается - визуализируем ложные срабатывания (false positives) и ложноотрицательные срабатывания (false negatives).\n",
        "\n",
        "Для этого мы прогоним модель через все примеры и сравним ее с истинными метками (ground truth)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieEzZUglJAUB"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.sampler import Sampler\n",
        "\n",
        "class SubsetSampler(Sampler):\n",
        "    r\"\"\"Samples elements with given indices sequentially\n",
        "\n",
        "    Arguments:\n",
        "        data_source (Dataset): dataset to sample from\n",
        "        indices (ndarray): indices of the samples to take\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, indices):\n",
        "        self.indices = indices\n",
        "\n",
        "    def __iter__(self):\n",
        "        return (self.indices[i] for i in range(len(self.indices)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "    \n",
        "    \n",
        "def evaluate_model(model, dataset, indices):\n",
        "    \"\"\"\n",
        "    Computes predictions and ground truth labels for the indices of the dataset\n",
        "    \n",
        "    Returns: \n",
        "    predictions: np array of booleans of model predictions\n",
        "    grount_truth: np array of boolean of actual labels of the dataset\n",
        "    \"\"\"\n",
        "    model.eval() # Evaluation mode\n",
        "    \n",
        "    # TODO: Evaluate model on the list of indices and capture predictions\n",
        "    # and ground truth labels\n",
        "    # Hint: SubsetSampler above could be useful!\n",
        "    \n",
        "    raise Exception(\"Not implemented\")\n",
        "    \n",
        "    return predictions, ground_truth\n",
        "\n",
        "predictions, gt = evaluate_model(model_conv, train_dataset, val_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0bcioK6JBDK"
      },
      "source": [
        "И теперь можно визуализировать false positives и false negatives."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMmaPfdeKk9H"
      },
      "outputs": [],
      "source": [
        "# TODO: Compute indices of the false positives on the validation set.\n",
        "# Note those have to be indices of the original dataset\n",
        "false_positive_indices = None\n",
        "visualize_samples(orig_dataset, false_positive_indices, \"False positives\")\n",
        "\n",
        "# TODO: Compute indices of the false negatives on the validation set.\n",
        "# Note those have to be indices of the original dataset\n",
        "false_negatives_indices = None\n",
        "visualize_samples(orig_dataset, false_negatives_indices, \"False negatives\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoDeVjN4HZSV"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as metrics\n",
        "def binary_classification_metrics(prediction, ground_truth):\n",
        "    # TODO: Implement this function!\n",
        "    # We did this already it in the assignment1\n",
        "    return precision, recall, f1\n",
        "\n",
        "precision, recall, f1 = binary_classification_metrics(predictions, gt)\n",
        "print(\"F1: %4.3f, P: %4.3f, R: %4.3f\" % (f1, precision, recall))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_O9qiYySvuj"
      },
      "source": [
        "# Что будет в конце вы уже поняли\n",
        "\n",
        "Натренируйте лучшую модель на основе `resnet18`, меняя только процесс тренировки.\n",
        "Выбирайте лучшую модель по F1 score.\n",
        "\n",
        "Как всегда, не забываем:\n",
        "- побольше аугментаций!\n",
        "- перебор гиперпараметров\n",
        "- различные оптимизаторы\n",
        "- какие слои тюнить\n",
        "- learning rate annealing\n",
        "- на какой эпохе останавливаться\n",
        "\n",
        "Наша цель - довести F1 score на validation set до значения, большего **0.93**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6mhfdQ9K-N3"
      },
      "outputs": [],
      "source": [
        "# TODO: Train your best model!\n",
        "best_model = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6xExdw8JB1l"
      },
      "outputs": [],
      "source": [
        "# Let's check how it performs on validation set!\n",
        "predictions, ground_truth = evaluate_model(best_model, dataset, val_indices)\n",
        "precision, recall, f1 = binary_classification_metrics(predictions, ground_truth)\n",
        "print(\"F1: %4.3f, P: %4.3f, R: %4.3f\" % (precision, recall, f1))\n",
        "\n",
        "# TODO: Visualize training curve for the best model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffHBW_gwYj6Q"
      },
      "source": [
        "## Визуализируйте ошибки лучшей модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFUeNOm1VACr"
      },
      "outputs": [],
      "source": [
        "# TODO Visualize false positives and false negatives of the best model on the validation set"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}